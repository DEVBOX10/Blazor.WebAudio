@page "/ApplyFilter"
@using KristofferStrube.Blazor.DOM
@using KristofferStrube.Blazor.MediaCaptureStreams;
@using KristofferStrube.Blazor.WebIDL;
@using KristofferStrube.Blazor.WebIDL.Exceptions;
@implements IAsyncDisposable
@inject IJSRuntime JSRuntime
@inject IMediaDevicesService MediaDevicesService
@inject HttpClient HttpClient
<PageTitle>WebAudio - Apply Filter</PageTitle>
<h2>Apply Filter</h2>

<p>
    On this page we first chain a <code>MediaStreamAudioSourceNode</code> through a <code>DelayNode</code> of 1 second, a <code>Lowpass</code> <code>BiquadFilterNode</code>, and a <code>ConvolverNode</code> with data from a big hall before connecting to the <code>AudioDestinationNode</code> of the <code>AudioContext</code> to output a delayed repeat of what you say with reverb.
</p>
<p>
    After this we can see a frequency diagram that shows the <u style="color:blue">original media stream</u> and the <u style="color:red">filtered media stream</u>. You can also change the frequency cut off with a slider to see how it influences the filtered sound. Only low frequencies will get through the filter if you decrease the cut off. You can imagine that this simulates that what you hear is further away in the big room as the low frequencies are the only ones left.
</p>


@if (error is { } errorMessage)
{
    <p style="color: red;">@errorMessage</p>
}
else if (mediaStreamAudioSourceNode is null)
{
    <button class="btn btn-primary" @onclick="OpenAudio">Load Audio</button>
}
else
{
    <DoublePlot Data1="filteredFrequencies" Data2="frequencies" />

    @if (BiquadFrecuencyParam is not null)
    {
        <AudioParamSlider AudioParam=BiquadFrecuencyParam Label="Frequency Cut Off" Min="0" Max="3000" StepSize="1" /><br />
    }

    @if (audioOptions.Count > 0)
    {
        <label for="audioSource">Audio Source</label>
        <select id="audioSource" @bind=selectedAudioSource @bind:after="OpenAudio">
            @foreach (var option in audioOptions)
            {
                <option value="@option.id" selected="@(option.id == selectedAudioSource)">@option.label</option>
            }
        </select>
    }
}

@code {
    AudioContext audioContext = default!;
    string? error;
    bool stopped;

    private byte[] filteredFrequencies = Array.Empty<byte>();
    private byte[] frequencies = Array.Empty<byte>();

    MediaDevices? mediaDevices;
    MediaStream? mediaStream;
    MediaStreamAudioSourceNode? mediaStreamAudioSourceNode;
    List<(string label, string id)> audioOptions = new();
    string? selectedAudioSource;

    AudioParam? BiquadFrecuencyParam;

    async Task OpenAudio()
    {
        await StopAudioTrack();

        try
        {
            if (audioContext is null)
            {
                audioContext = await AudioContext.CreateAsync(JSRuntime);
            }
            if (mediaDevices is null)
            {
                mediaDevices = await MediaDevicesService.GetMediaDevicesAsync();
            }

            MediaTrackConstraints mediaTrackConstraints = new MediaTrackConstraints
                {
                    EchoCancellation = true,
                    NoiseSuppression = true,
                    AutoGainControl = false,
                    DeviceId = selectedAudioSource is null ? null : new ConstrainDomString(selectedAudioSource)
                };
            mediaStream = await mediaDevices.GetUserMediaAsync(new MediaStreamConstraints() { Audio = mediaTrackConstraints });

            var deviceInfos = await mediaDevices.EnumerateDevicesAsync();
            audioOptions.Clear();
            foreach (var device in deviceInfos)
            {
                if (await device.GetKindAsync() is MediaDeviceKind.AudioInput)
                {
                    audioOptions.Add((await device.GetLabelAsync(), await device.GetDeviceIdAsync()));
                }
            }

            mediaStreamAudioSourceNode = await audioContext.CreateMediaStreamSourceAsync(mediaStream);

            BiquadFilterOptions options = new()
            {
                Type = BiquadFilterType.Lowpass,
                Frequency = 2000
            };

            byte[] bufferData = await HttpClient.GetByteArrayAsync("Data/BIG HALL E001 M2S.wav");
            var audioBuffer = await audioContext.DecodeAudioDataAsync(bufferData);

            var convolver = await ConvolverNode.CreateAsync(JSRuntime, audioContext, new() { Buffer = audioBuffer });
            var destination = await audioContext.GetDestinationAsync();
            var delayNode = await DelayNode.CreateAsync(JSRuntime, audioContext, new() { DelayTime = 0.01, MaxDelayTime = 1 });
            var filterNode = await BiquadFilterNode.CreateAsync(JSRuntime, audioContext, options);
            var filteredAnalyserNode = await audioContext.CreateAnalyserAsync();
            var analyserNode = await audioContext.CreateAnalyserAsync();

            BiquadFrecuencyParam = await filterNode.GetFrequencyAsync();
            
            await mediaStreamAudioSourceNode.ConnectAsync(delayNode);
            await delayNode.ConnectAsync(convolver);
            await convolver.ConnectAsync(filterNode);
            await delayNode.ConnectAsync(analyserNode);
            await filterNode.ConnectAsync(destination);
            await filterNode.ConnectAsync(filteredAnalyserNode);

            await Task.Delay(500);

            int bufferLength = (int)await analyserNode.GetFrequencyBinCountAsync();
            var dataArray = await Uint8Array.CreateAsync(JSRuntime, bufferLength);

            int filteredBufferLength = (int)await filteredAnalyserNode.GetFrequencyBinCountAsync();
            var filteredDataArray = await Uint8Array.CreateAsync(JSRuntime, filteredBufferLength);

            stopped = false;
            while (!stopped)
            {
                await analyserNode.GetByteFrequencyDataAsync(dataArray);
                await filteredAnalyserNode.GetByteFrequencyDataAsync(filteredDataArray);

                frequencies = await dataArray.GetAsArrayAsync();
                filteredFrequencies = await filteredDataArray.GetAsArrayAsync();
                await Task.Delay(1);
                StateHasChanged();
            }
        }
        catch (Exception ex)
        {
            error = $"{ex.GetType().Name}: {ex.Message}";
        }
    }

    async Task StopAudioTrack()
    {
        stopped = true;
        if (mediaStream is null) return;
        var audioTrack = (await mediaStream.GetAudioTracksAsync()).FirstOrDefault();
        if (audioTrack is not null)
        {
            await audioTrack.StopAsync();
        }
    }

    public async ValueTask DisposeAsync()
    {
        await StopAudioTrack();
    }
}


